{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIG Notice!!!\n",
    "All the output of the file is what I received from CCGrep tool manually. So the codes below just illustrate how my project works. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------DATA CLEANING PART------------------------------------\n",
    "#### The function is used for cleaning up the data and transform it into form of CSV file\n",
    "#### To call the function replace \"fin\" with the address of the target file that is needed to be cleaned and \"fout\" with the address of the expected output with the desired filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_up_csv(fin,fout):\n",
    "\n",
    "    with open(fin, \"r\") as f:\n",
    "        data = list(csv.reader(f))\n",
    "        data = [[i[0].replace(\":\",\",\"),i[1]] for i in data]\n",
    "        \n",
    "\n",
    "    with open(fout, \"w\", newline='') as f:\n",
    "        print(\"Package,Filename,Count,Date,Version\",file=f)\n",
    "        for row in data:\n",
    "                temp=row[0].split(',')\n",
    "                temp2 = temp[1].split('{')\n",
    "                temp3=temp[0].split('/')\n",
    "                if \"0\" not in temp2[0]:\n",
    "                    print(temp3[len(temp3)-2]+\",\"+temp3[len(temp3)-1]+\",\"+temp2[0]+\",\"+temp2[1]+\",\"+row[1],file = f)             \n",
    "    return fout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To plot the graph, the the axes must contain all of the ranges in every file \n",
    "#### To call the fuction, replace \"dire\" with the address of the folder that all of the needed files located and replace \"fname\" with what ever you want to name the new combined file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function is for combining all the dataset used in the graph so the axes contain all of the ranges we need \n",
    "def combine_csv(dire,fname):\n",
    "    \n",
    "    os.chdir(dire)\n",
    "    extension = 'csv'\n",
    "    all_filenames = [i for i in glob.glob('*.{}'.format(extension))]\n",
    "    #combine all files in the list\n",
    "    combined_csv = pd.concat([pd.read_csv(f) for f in all_filenames ])\n",
    "    #export to csv\n",
    "    combined_csv.to_csv(fname,index=False, encoding='utf-8-sig')\n",
    "    return dire + \"/\" + fname\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------GRAPH PLOTTING PART------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import pi\n",
    "from datetime import datetime as dt\n",
    "from bokeh.io import output_notebook,show\n",
    "from bokeh.models import DatetimeTickFormatter,ColumnDataSource\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.transform import jitter\n",
    "from bokeh.layouts import column,gridplot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is Graph 1: Non-idiomatic and Idiomatic Code Occurences in Packages of a Project\n",
    "\n",
    "#### To call function, replace \"cbad\" with file address of the cleaned non-idiomatic output, \"cgood\" with file address of the cleaned idiomatic output, and \"ctotal\" with address of the combined good and bad output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph1(cbad,cgood,ctotal):\n",
    "    \n",
    "    output_notebook()\n",
    "\n",
    "    bad = pd.read_csv(cbad)\n",
    "    bad['Date'] = pd.to_datetime(bad['Date'],format='%Y-%m-%d')\n",
    "    bad['Count'] = bad['Count']*10\n",
    "\n",
    "    good = pd.read_csv(cgood)\n",
    "    good['Date'] = pd.to_datetime(good['Date'],format='%Y-%m-%d')\n",
    "    good['Count'] = good['Count']*10\n",
    "\n",
    "    total = pd.read_csv(ctotal)\n",
    "\n",
    "    sourcebad = ColumnDataSource(bad)\n",
    "    sourcegood = ColumnDataSource(good)\n",
    "\n",
    "    packs = total['Package'].unique().astype('str')\n",
    "\n",
    "\n",
    "    p=figure(x_axis_type='datetime',y_range = packs,plot_width = 900,title=\"Non-idiomatic and Idiomatic Code Occurences in Packages of a Project\",tools=['wheel_zoom','pan','reset'])\n",
    "\n",
    "\n",
    "    p.circle(x='Date', y=jitter('Package', width=0.6, range=p.y_range),size =10, source=bad,color='red',alpha=0.2,legend = 'Non-idiomatic')\n",
    "    p.circle(x='Date', y=jitter('Package', width=0.6, range=p.y_range),size =10, source=good,color='green',alpha=0.2,legend = 'Idiomatic')\n",
    "\n",
    "    p.yaxis.axis_label = \"Packages\"\n",
    "    p.xaxis.axis_label = \"Time\"\n",
    "    p.xaxis.formatter=DatetimeTickFormatter(days = [\"%Y/%m/%d\" ])\n",
    "\n",
    "    p.legend.location = \"top_right\"\n",
    "    p.legend.click_policy=\"hide\"\n",
    "    show(p)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before using this graph, please extract files first \n",
    "This is the how to extract output files into versions manually\n",
    "\n",
    " If the project contains only good or bad idioms, go to case 1.\n",
    " If the project contains both good and bad idioms, go to case 2.\n",
    " \n",
    " Case 1:\n",
    " 1. Create a new file\n",
    " 2. Insert the heading for the columns  --->> Package,Filename,Count,Date,Version \n",
    " 3. Open the target output file that is needed to be extracted\n",
    " 4. Copy every rows of the first version that are shown in the target output file \n",
    " 5. Paste them in the new created file.\n",
    " 6. Do step 1 to 5 for the last version also\n",
    " \n",
    " Case 2:\n",
    " 1. Create two new files, one for the good and one for the bad.\n",
    " 2. Insert the heading for the columns  --->> Package,Filename,Count,Date,Version in both two files\n",
    " 3. Open the both good and bad cleaned output.\n",
    " 4. Compare the first version of both files. If they are the same version, copy and paste the first version of both good and bad in the new files.\n",
    " 5. If they are not the same, use the older version of one of the file and copy and past that one in the new file depends on if it is good or bad output\n",
    " 6. Do step 1 to 5 for the last version but in step 5, change from use the older one to the newer one.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is Graph 2:  Non-idiomatic and Idiomatic Code Occurences in Each Files of the First and Last Version\n",
    "#### To call the functoin, replace \"badf\" with the address of the first non-diomatic file, replace \"badl\" with the address of the last non-idiomatic version file, replace \"goodf\" with the address of the first idiomatic version file, replace \"goodl\" with the address of the last idiomatic version file, and replace \"comb\" with the address of the file that combines all of the first 4 previous files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph2(badf,badl,goodf,goodl,comb):\n",
    "    \n",
    "    output_notebook()\n",
    "\n",
    "    #read from file\n",
    "    badfirst = pd.read_csv(badf)\n",
    "    badlast = pd.read_csv(badl)\n",
    "    goodfirst = pd.read_csv(goodf)\n",
    "    goodlast = pd.read_csv(goodl)\n",
    "    total = pd.read_csv(comb)\n",
    "\n",
    "    sourcebadfirst = ColumnDataSource(badfirst)\n",
    "    sourcebadlast = ColumnDataSource(badlast)\n",
    "    sourcegoodfirst = ColumnDataSource(goodfirst)\n",
    "    sourcegoodlast = ColumnDataSource(goodlast)\n",
    "    sourcetotal = ColumnDataSource(total)\n",
    "\n",
    "    count = total['Count'].unique()\n",
    "    file = total['Filename'].unique()\n",
    "\n",
    "    left = figure(x_range = file,plot_width = 900,title=\"Non-idiomatic and Idiomatic Code Occurences in Each Files of the First Version\",\n",
    "                  tools=['wheel_zoom','pan','reset'])\n",
    "    right = figure(x_range = file,plot_width = 900,title=\"Non-idiomatic and Idiomatic Code Occurences in Each Files of the Last Version\",\n",
    "                   tools=['wheel_zoom','pan','reset'])\n",
    "\n",
    "\n",
    "    left.yaxis.axis_label = \"Count\"\n",
    "    left.xaxis.axis_label = \"Filename\"\n",
    "    left.xaxis.major_label_orientation = np.pi/3\n",
    "    left.yaxis.major_label_orientation = np.pi/3\n",
    "\n",
    "    right.yaxis.axis_label = \"Count\"\n",
    "    right.xaxis.axis_label = \"Filename\"\n",
    "    right.xaxis.major_label_orientation = np.pi/3\n",
    "    right.yaxis.major_label_orientation = np.pi/3\n",
    "\n",
    "\n",
    "    left.vbar(x='Filename', top='Count', source = badfirst,width=0.9,color='red',alpha=0.2,legend ='Non-idiomatic')\n",
    "    left.vbar(x='Filename', top='Count', source = goodfirst,width=0.9,color='green',alpha=0.2,legend ='Idiomatic')\n",
    "    right.vbar(x='Filename', top='Count', source = badlast,width=0.9,color='red',alpha=0.2,legend ='Non-idiomatic')\n",
    "    right.vbar(x='Filename', top='Count', source = goodlast,width=0.9,color='green',alpha=0.2,legend ='Idiomatic')\n",
    "\n",
    "    left.y_range.start = 0\n",
    "    right.y_range.start = 0\n",
    "\n",
    "    left.legend.location = \"top_right\"\n",
    "    left.legend.click_policy=\"hide\"\n",
    "    right.legend.location = \"top_right\"\n",
    "    right.legend.click_policy=\"hide\"\n",
    "\n",
    "    p = gridplot([[left, right]])\n",
    "    #show(column(left, right))\n",
    "    show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good\n",
      "bad\n",
      "toto/lala/tata\n"
     ]
    }
   ],
   "source": [
    "#This is the example of how the functions are called\n",
    "\n",
    "#Declaring functions\n",
    "def clean(fout):\n",
    "    return fout\n",
    "def combine(dir,name):\n",
    "    return dir + \"/\" +name\n",
    "def plot(good,bad,total):\n",
    "    print(good)\n",
    "    print(bad)\n",
    "    print(total)\n",
    "#1.clean the data first   \n",
    "aa = clean(fout='good')\n",
    "bb = clean(fout='bad')\n",
    "#2.combine those two\n",
    "cc = combine(dir='toto/lala',name='tata')\n",
    "#3.plot the graph    \n",
    "plot(good = aa,bad =bb,total = cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'your csv file directory'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-6b9511bf9c0b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m cleanbad = clean_up_csv(fin = \"your csv file directory\",\n\u001b[1;32m----> 4\u001b[1;33m                         fout = \"your csv file directory\")\n\u001b[0m\u001b[0;32m      5\u001b[0m cleangood = clean_up_csv(fin =\"your csv file directory\",\n\u001b[0;32m      6\u001b[0m                          fout = \"your csv file directory\")\n",
      "\u001b[1;32m<ipython-input-1-ec761aa3fe78>\u001b[0m in \u001b[0;36mclean_up_csv\u001b[1;34m(fin, fout)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mclean_up_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\":\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'your csv file directory'"
     ]
    }
   ],
   "source": [
    "#clean data\n",
    "\n",
    "cleanbad = clean_up_csv(fin = \"your csv file directory\",\n",
    "                        fout = \"your csv file directory\")\n",
    "cleangood = clean_up_csv(fin =\"your csv file directory\",\n",
    "                         fout = \"your csv file directory\")\n",
    "\n",
    "#combine data\n",
    "combine = combine_csv(dire = \"your file director\",fname = \"your file name\")\n",
    "#plot!!!!\n",
    "plot_graph1(cbad = cleanbad ,cgood = cleangood ,ctotal = combine)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph2(badf=\"your csv file directory\",\n",
    "            badl=\"your csv file directory\",\n",
    "            goodf=\"your csv file directory\",\n",
    "            goodl=\"your csv file directory\",\n",
    "            comb=\"your csv file directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
